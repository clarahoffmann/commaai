{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import helpers as hlp\n",
    "import numpy as np\n",
    "import numpy as np\n",
    "import helpers as hlp\n",
    "import math\n",
    "from random import random, seed\n",
    "from numpy.linalg import multi_dot\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm\n",
    "from scipy.stats import multivariate_normal"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_coefficients_path = '../../../../data/commaai/extracted_coefficients/20201021_unrestr_gaussian_resampled/'\n",
    "B_zeta_path = str(extracted_coefficients_path + 'Bzeta/B_zeta.npy')\n",
    "beta_path = str(extracted_coefficients_path + 'beta/beta.csv')\n",
    "z_path = str(extracted_coefficients_path + 'Bzeta/tr_labels.npy')\n",
    "\n",
    "beta = np.genfromtxt(beta_path, delimiter=',')\n",
    "# B_zeta is a n x q matrix\n",
    "B_zeta = np.load(B_zeta_path)\n",
    "B_zeta = B_zeta.reshape(B_zeta.shape[0], beta.shape[0])\n",
    "tBB = B_zeta.T.dot(B_zeta)\n",
    "z = np.load(z_path) #[0:B_zeta.shape[0]]\n",
    "\n",
    "# p is the number of beta coefficients in the last hidden layer\n",
    "p = B_zeta.shape[1]\n",
    "\n",
    "\n",
    "# Lambda is a diagonal matrix of dimension p\n",
    "Lambda = np.diag(np.random.rand(p,))\n",
    "\n",
    "seed(679305)\n",
    "tau_start = 0.01\n",
    "\n",
    "# Set iteration counter to 0\n",
    "t = 0\n",
    "\n",
    "theta = 2.5\n",
    "\n",
    "n = B_zeta.shape[0]\n",
    "\n",
    "# S(x, theta) is of dimension n x n\n",
    "W = np.array([B_zeta[i,:].dot(B_zeta[i,:]) for i in range(0, n)])\n",
    "S = np.sqrt(1/(1 + W*tau_start))\n",
    "S2 = S**2\n",
    "\n",
    "# m is number of variational parameters, which is \n",
    "# 2p (for each lambda_j and each beta_j)\n",
    "# plus the variational parameter for the prior on lambda\n",
    "m = p + 1\n",
    "\n",
    "# number of factors in the factored covariance representation\n",
    "k = 10\n",
    "\n",
    "mu_t = np.array([random() for i in range(0,m)]).reshape(m,1)\n",
    "# B is a lower triangle m x k matrix and is the first component of the \n",
    "# covariance matrix\n",
    "B_t = np.tril(np.random.rand(m,k))\n",
    "while not np.linalg.matrix_rank(B_t) == k:\n",
    "    B_t = np.tril(np.random.rand(m,k))\n",
    "\n",
    "# D is a diagonal matrix of dimension m x m and is the second component of the \n",
    "# covariance matrix\n",
    "D_t = np.diag(np.repeat(1,m))\n",
    "d_t = np.diag(D_t).reshape(m,1)\n",
    "\n",
    "mean_epsilon = np.repeat(0, m)\n",
    "mean_z = np.repeat(0, k)\n",
    "\n",
    "var_epsilon = np.diag(np.repeat(1,m))\n",
    "var_z = np.diag(np.repeat(1,k))\n",
    "\n",
    "## Adadelta\n",
    "decay_rate = 0.95\n",
    "constant = 1e-7\n",
    "E_g2_t_1 = 0\n",
    "E_delta_x_2_1 = 0\n",
    "\n",
    "E_g2_t_1_mu = np.repeat(0, len(mu_t))\n",
    "E_delta_x_2_1_mu = np.repeat(0, len(mu_t))\n",
    "E_g2_t_1_B = np.zeros(B_t.shape)\n",
    "E_delta_x_2_1_B = np.zeros(B_t.shape)\n",
    "E_g2_t_1_d = np.repeat(0, len(d_t)).reshape(m,1)\n",
    "E_delta_x_2_1_d = np.repeat(0, len(d_t)).reshape(m,1)\n",
    "\n",
    "def adadelta_change(gradient, E_g2_t_1, E_delta_x_2_1, decay_rate = 0.99, constant = 10e-6):\n",
    "    # expected squared gradient for next iteration\n",
    "    E_g2_t = decay_rate*E_g2_t_1 + (1 - decay_rate)*(gradient**2)\n",
    "    # update for parameter\n",
    "    # should there be a minus or plus here ?????\n",
    "    delta_x =  (np.sqrt(E_delta_x_2_1 + constant)/np.sqrt(E_g2_t + constant))*gradient\n",
    "    # expected update for next iteration\n",
    "    E_delta_x_2 = decay_rate*E_delta_x_2_1 + (1 - decay_rate)*(delta_x**2)\n",
    "    return(delta_x, E_g2_t, E_delta_x_2 )\n",
    "\n",
    "lower_bounds = []\n",
    "all_varthetas = []\n",
    "d_ts = []\n",
    "mu_ts = []\n",
    "d_ts = []\n",
    "B_ts = []\n",
    "t = 0\n",
    "\n",
    "n = 100\n",
    "iterations = 8000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor10_100.npy'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-5-1e4e50fbce89>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mlower_bounds\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/lower_bounds_factor_50.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mall_varthetas\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor10_100.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mmu_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/mu_ts23_factor10_100.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0md_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/d_ts23_factor10_100.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mB_ts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/B_ts23_factor10_100.npy'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtolist\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/numpy/lib/npyio.py\u001b[0m in \u001b[0;36mload\u001b[0;34m(file, mmap_mode, allow_pickle, fix_imports, encoding)\u001b[0m\n\u001b[1;32m    414\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    415\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 416\u001b[0;31m             \u001b[0mfid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mstack\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menter_context\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mopen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mos_fspath\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfile\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m\"rb\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    417\u001b[0m             \u001b[0mown_fid\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    418\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor10_100.npy'"
     ]
    }
   ],
   "source": [
    "#lower_bounds = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/lower_bounds_factor_50.npy')\n",
    "#all_varthetas = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor10_100.npy')\n",
    "#mu_ts = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/mu_ts23_factor10_100.npy').tolist()\n",
    "#d_ts = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/d_ts23_factor10_100.npy').tolist()\n",
    "#B_ts = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/B_ts23_factor10_100.npy').tolist()\n",
    "#all_varthetas = all_varthetas[-1:].tolist()\n",
    "#lower_bounds = lower_bounds.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#mu_t = np.array(mu_ts[-1])\n",
    "#d_t = np.array(d_ts[-1])\n",
    "#B_t = np.array(B_ts[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in tqdm(range(iterations)):\n",
    "    \n",
    "    # 1. Generate epsilon_t and z_t\n",
    "    z_t = hlp.generate_z(mean_z,var_z, n)\n",
    "    epsilon_t = hlp.generate_epsilon(mean_epsilon, var_epsilon, n)\n",
    "    \n",
    "    # 2. Draw from vartheta, what we generate are log values\n",
    "    # of lambda and tau -> have to transform them back to use them\n",
    "\n",
    "    \n",
    "    # Compute inverse with Woodbury formula.\n",
    "    inv = np.diag(1/(np.diag(D_t**2)))\n",
    "    inv2 = np.linalg.inv(np.identity(k) + B_t.T.dot(inv).dot(B_t))\n",
    "    BBD_inv = inv - multi_dot([inv, B_t, inv2, B_t.T, inv])\n",
    "\n",
    "    for i in range(0, n):\n",
    "        \n",
    "        z_t_i = z_t[i,:].reshape(k,1)\n",
    "        epsilon_t_i = epsilon_t[i,:].reshape(11,1)\n",
    "        vartheta_t = mu_t + B_t.dot(z_t_i) +  (d_t*epsilon_t_i)\n",
    "        beta_t = vartheta_t[0:p].reshape(p,)\n",
    "        betaBt_t = beta_t.dot(B_zeta.T)\n",
    "    \n",
    "        # 3. Compute gradient of beta, lambda_j, and tau\n",
    "        gradient_h_t = hlp.Delta_theta(vartheta_t, B_zeta, n, z, p, tBB, betaBt_t, theta, W)\n",
    "\n",
    "        # Compute gradients for the variational parameters mu, B, D\n",
    "        Delta_mu = hlp.Delta_mu(gradient_h_t, BBD_inv, z_t_i, d_t, epsilon_t_i, B_t)\n",
    "        Delta_B = hlp.Delta_B(B_zeta,n,z, p, B_t, gradient_h_t, z_t_i, D_t, d_t, epsilon_t_i, BBD_inv)\n",
    "        Delta_D = hlp.Delta_D(gradient_h_t, epsilon_t_i, D_t, d_t,p, BBD_inv, B_t, z_t_i).reshape(11,1)\n",
    "        \n",
    "        if i == 0:\n",
    "            Delta_mu_mean = Delta_mu/n\n",
    "            Delta_B_mean = Delta_B/n\n",
    "            Delta_D_mean = Delta_D/n\n",
    "        elif i > 0:\n",
    "            Delta_mu_mean += Delta_mu/n\n",
    "            Delta_B_mean += Delta_B/n\n",
    "            Delta_D_mean += Delta_D/n\n",
    "        \n",
    "        \n",
    "    \n",
    "    # 4. Adadelta Updates\n",
    "    update_mu, E_g2_t_1_mu, E_delta_x_2_1_mu = adadelta_change(Delta_mu_mean, E_g2_t_1_mu, E_delta_x_2_1_mu, decay_rate = decay_rate, constant = constant)\n",
    "    update_B, E_g2_t_1_B, E_delta_x_2_1_B  = adadelta_change(Delta_B_mean, E_g2_t_1_B, E_delta_x_2_1_B, decay_rate = decay_rate, constant = constant)\n",
    "    update_d, E_g2_t_1_d, E_delta_x_2_1_d = adadelta_change(Delta_D_mean, E_g2_t_1_d, E_delta_x_2_1_d, decay_rate = decay_rate, constant = constant)\n",
    "    \n",
    "    # Update variables\n",
    "    mu_t = mu_t + update_mu.reshape(m,1)\n",
    "    B_t = B_t + update_B\n",
    "    # set upper triangular elements to 0\n",
    "    B_t *= np.tri(*B_t.shape)\n",
    "    d_t = (d_t + update_d)\n",
    "    D_t = np.diag(d_t.reshape(m,))\n",
    "    \n",
    "    for i in range(0, n):\n",
    "        z_t_i = z_t[i,:].reshape(k,1)\n",
    "        epsilon_t_i = epsilon_t[i,:].reshape(11,1)\n",
    "        vartheta_t = mu_t + B_t.dot(z_t_i) +  (d_t*epsilon_t_i)\n",
    "        vartheta_t_transf = vartheta_t.copy()\n",
    "\n",
    "        # 5. compute stopping criterion\n",
    "        beta_t = vartheta_t_transf[0:p].reshape(p,)\n",
    "        u_t = vartheta_t_transf[p]\n",
    "        betaBt_t = beta_t.dot(B_zeta.T) \n",
    "\n",
    "        S = np.sqrt(1/(1 + W*np.exp(u_t)))\n",
    "        S2 = S**2\n",
    "\n",
    "        # Lower bound L(lambda) = E[log(L_lambda - q_lambda]\n",
    "        log_h_t = hlp.log_density(z, u_t,  beta_t, B_zeta, p, n, S, S2, tBB, theta, betaBt_t)\n",
    "        log_q_lambda_t = np.log(multivariate_normal.pdf(vartheta_t.reshape(11,), mu_t.reshape(11), (B_t.dot(B_t.T) + D_t**2)))\n",
    "        \n",
    "        if i == 0:\n",
    "            L_lambda_mean = (log_h_t - log_q_lambda_t)/n\n",
    "        elif i > 0:\n",
    "            L_lambda_mean += (log_h_t - log_q_lambda_t)/n\n",
    "    \n",
    "    # evidence lower bound\n",
    "    lower_bounds.append(L_lambda_mean.item())\n",
    "    all_varthetas.append(vartheta_t)\n",
    "    mu_ts.append(mu_t)\n",
    "    d_ts.append(d_t)\n",
    "    B_ts.append(B_t)\n",
    "    \n",
    "    # increase time count\n",
    "    t = t+1\n",
    "\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/lower_bounds_factor_100.npy', lower_bounds)\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor_100.npy', np.array(all_varthetas))\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/mu_ts23_factor_100.npy', mu_ts)\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/d_ts23_factor_100.npy', d_ts)\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/B_ts23_factor_100.npy', B_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/lower_bounds_factor10_100.npy', lower_bounds)\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor10_100.npy', np.array(all_varthetas))\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/mu_ts23_factor10_100.npy', mu_ts)\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/d_ts23_factor10_100.npy', d_ts)\n",
    "np.save('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/B_ts23_factor10_100.npy', B_ts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower_bounds = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/lower_bounds_factor_100.npy')\n",
    "#all_varthetas = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/vartheta_factor_100.npy')\n",
    "#mu_ts = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/mu_ts23_factor_100.npy')\n",
    "#d_ts = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/d_ts23_factor_100.npy')\n",
    "#B_ts = np.load('../../../../data/commaai/va/unfiltered_gaussian_resampled/Ridge/B_ts23_factor_100.npy' )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(lower_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lower_bounds)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_ts_m = np.mean(np.array(B_ts)[6000:,:,:], axis = 0)\n",
    "d_ts_m = np.mean(np.array(d_ts)[6000:,:,:], axis = 0)\n",
    "mu_ts_m = np.mean(np.array(mu_ts)[6000:,:,:], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_va = np.sqrt(np.diag(B_ts_m.dot(B_ts_m.T) + d_ts_m**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var_va"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_thetas = np.load('../../../../data/commaai/mcmc/unfiltered_gaussian_resampled/Ridge/all_thetas_L100_5000.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mcmc_mean = np.mean(all_thetas[1000:,:], axis = 0)\n",
    "mcmc_sd = np.std(all_thetas[1000:,:], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(all_thetas)\n",
    "#plt.ylim(-.4,.4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(mu_ts_m[0:10], mcmc_mean[0:10])\n",
    "ident = [-1, 1]\n",
    "plt.plot(ident,ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(var_va, mcmc_sd)\n",
    "ident = [0, 0.3]\n",
    "plt.plot(ident,ident)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
