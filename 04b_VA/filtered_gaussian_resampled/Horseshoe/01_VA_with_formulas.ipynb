{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers as hlp\n",
    "import math\n",
    "from random import random, seed\n",
    "from numpy.linalg import multi_dot\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\"\n",
    "        src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
    "\n",
    "## Model\n",
    "Linear model\n",
    "\\\\[ \\tilde{\\boldsymbol{Z}} = B_{\\boldsymbol{\\zeta}}(\\boldsymbol{x})\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon} \\, \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2I) \\\\]\n",
    "\n",
    "and the transformed target variables follow a conditional normal distribution\n",
    "\n",
    "\\\\[ \\boldsymbol{Z} | \\boldsymbol{x}, \\sigma^2, \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{0}, R(\\boldsymbol{x}, \\boldsymbol{\\theta})^T) \\\\]\n",
    "with $ R(\\boldsymbol{x}, \\boldsymbol{\\theta}) = S(\\boldsymbol{x}, \\boldsymbol{\\theta})(I - B\\Omega B^T)^{-1}S(\\boldsymbol{x}, \\boldsymbol{\\theta})^T $\n",
    "\n",
    "and each Z_i has a marginal standard-normal distribution.\n",
    "\n",
    "The coefficient vector beta follows a conditional normal distribution\n",
    "\n",
    "\\\\[ \\boldsymbol{\\beta} | \\boldsymbol{x}, \\sigma^2, \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\sigma^2 P(\\boldsymbol{\\theta})^{-1}) \\\\]\n",
    "\n",
    "\n",
    "## Prior on copula parameters\n",
    "\n",
    "Horseshoe prior on coefficients\n",
    "\\\\[\\beta_j| \\lambda_j \\sim \\mathcal{N}(0,\\lambda_j^2) \\\\]\n",
    "with $\\pi_0(\\lambda_j | \\tau) = C^{+}(0,\\tau) $ and $ \\pi_0(\\tau) = C^{+}(0,1)$, where $C^{+}$ is the half-Cauchy distribution\n",
    "\n",
    "Then the vector of copula parameters is\n",
    "\\\\[\\boldsymbol{\\theta} = \\{ \\boldsymbol{\\lambda}, \\tau \\} \\\\]\n",
    "with \n",
    "\\\\[ \\boldsymbol{\\lambda} = (\\lambda_1,...\\lambda_p)^T \\\\]\n",
    "\n",
    "\\begin{equation}\n",
    "   P(\\boldsymbol{\\theta}) = diag(\\lambda_1^2,...\\lambda_p^2)^{-1}\n",
    "\\end{equation}\n",
    "and \n",
    "\\\\[ R(\\boldsymbol{x}, \\boldsymbol{\\theta}) = S(\\boldsymbol{x}, \\boldsymbol{\\theta}(I + B \\mathrm{diag}(\\lambda_1, ... \\lambda_p)^2 B ^T)S(\\boldsymbol{x}, \\boldsymbol{\\theta}) \\\\]\n",
    "\n",
    "\n",
    " - > so is P(theta) then just diag(phi_i)?\n",
    "Distribution of targets y\n",
    "\n",
    "\\\\[ p(\\boldsymbol{y}| \\boldsymbol{x}, \\boldsymbol{\\beta}, \\boldsymbol{\\theta}) = \\phi_n(\\boldsymbol{z};S(\\boldsymbol{x}, \\boldsymbol{\\theta})B_{\\boldsymbol{\\zeta}}\\boldsymbol{\\beta}, S(\\boldsymbol{x}, \\boldsymbol{\\theta})^2) \\prod_{i=1}^n \\frac{p_Y(y_i)}{\\phi_1(z_i)}, \\\\]\n",
    "with\n",
    "\n",
    "\\\\[ S(\\boldsymbol{x}, \\boldsymbol{\\theta}) = diag(s_1,...,s_n) \\\\]\n",
    "\n",
    "with $ s_i = (1+ \\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^TP(\\boldsymbol{\\theta})^{-1}\\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^{-\\frac{1}{2}}) $\n",
    "\n",
    "and specifically for the horseshoe prior case:\n",
    "\\\\[s_i = (1+ \\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^T P(\\boldsymbol{\\theta})^{-1}\\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^{-\\frac{1}{2}} \\\\]\n",
    "\n",
    "\n",
    "Now we want to optimize the ELBO which is given by\n",
    "\\\\[ \\mathcal{L}(\\lambda) = \\mathbb{E}_q[\\log h(\\vartheta) - \\log q_{\\lambda}(\\vartheta) ] \\\\]\n",
    "\n",
    "where $\\vartheta = \\{\\beta, \\theta \\}$ and $h(\\vartheta) = p(\\vartheta)p(y|\\vartheta)$.\n",
    "We want to estimate the augmented posteriors $\\beta, \\theta | \\boldsymbol{y}$\n",
    "\n",
    "\n",
    "## VA with factor covariance structure\n",
    "\n",
    "Choose an approximating family $ q_{\\lambda}(\\vartheta) $, in our case this is \n",
    "\\begin{equation}\n",
    "q_{\\lambda}(\\vartheta) = \\mathcal{N}(\\boldsymbol{\\mu}, BB^T + D^2),\n",
    "\\end{equation}\n",
    "with $d = \\{d_1,...d_m \\}$. The dimension of this distribution is $m$ and in the case of the horseshoe prior this is # of betas + 1 (tau) $= p+1$. The dimension of $B$ is $m \\times k$, where $k$ specifies the number of factors. To make computation easier $k$ should be much smaller than $m$. This implies that we can represent the dependency structure in the covariance matrix with a smaller number of latent variables, thus facilitating faster computation.\n",
    "\n",
    "How can we draw from this distribution?\n",
    "- first draw $(\\boldsymbol{z}, \\boldsymbol{\\epsilon}) \\sim \\mathcal{N}(0,I)$, where $\\boldsymbol{z}$ is of dimension $k \\times 1 $ and $\\boldsymbol{\\epsilon}$ is $m \\times 1$\n",
    "- then calculate $\\vartheta = \\boldsymbol{\\mu} + B\\boldsymbol{z} + d \\circ \\epsilon$, where $\\circ$ denotes the Hadamard product, i.e. the element by element multiplication of two vectors.\n",
    "\n",
    "By applying the reparametrization trick we can now change the  expectation with regard to $q_{\\lambda}(\\theta)$, namely $\\mathbb{E}_q$ to an expectation with regard to standard normal density of $z, \\epsilon$, which is denoted as $f(z, \\epsilon)$, which leads to the expectation $\\mathbb{E}_f$.\n",
    "Instead of evaluating the first time of the ELBO at $\\theta$, we evaluate it at the reparametarized $\\theta = \\mu + Bz + d \\circ \\epsilon$.\n",
    "The expectation with regard to $f$, $\\mathbb{E}_f$, can be estimated unbiasedly by generating one or more samples from $f$.\n",
    "\n",
    "Calculating the gradients delivers:\n",
    "- gradient w.r.t $\\mu$, i.e. mean of variational parameters $\\nabla_{\\mu} \\mathcal{L}(\\lambda) = \\mathbb{E}_f[\\nabla_{\\vartheta} \\log h(\\mu + Bz + d \\circ \\epsilon)]$\n",
    "- gradient w.r.t. $B$, i.e. first component of covariance matrix of variational parameters $\\nabla_B \\mathcal{L}(\\lambda) = \\mathbb{E}_f[ \\nabla_{\\vartheta} \\log h(\\mu + Bz + d \\circ \\epsilon)z^T + (BB^T + D^2)^{-1}(Bz+d \\circ \\epsilon)z^T]$\n",
    "- gradient w.r.t. $D = \\mathrm{diag}(d_1,...,d_n)$, i.e. the second component of covariance matrix of variational parameters $\\nabla_d \\mathcal{L}(\\lambda) = \\mathbb{E}_f[\\mathrm{diag}(\\nabla_{\\vartheta} \\log h(\\mu + Bz + d \\circ \\epsilon) \\epsilon^T + (BB^T + D^2)^{-1}(Bz + d \\circ \\epsilon) \\epsilon^T] $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Initialize $\\lambda = \\lambda^{(0)} = (\\mu^{(0)}, B^{(0)}, d^{(0)})$, $t = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load variables from training DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_coefficients_path = '../../../../data/commaai/extracted_coefficients/20201027_filtered_gaussian_resampled/'\n",
    "B_zeta_path = str(extracted_coefficients_path + 'Bzeta/B_zeta.npy')\n",
    "beta_path = str(extracted_coefficients_path + 'beta/beta.csv')\n",
    "z_path = str(extracted_coefficients_path + 'Bzeta/tr_labels.npy')\n",
    "\n",
    "beta = np.genfromtxt(beta_path, delimiter=',')\n",
    "# B_zeta is a n x q matrix\n",
    "B_zeta = np.load(B_zeta_path)\n",
    "B_zeta = B_zeta.reshape(B_zeta.shape[0], beta.shape[0])\n",
    "tBB = B_zeta.T.dot(B_zeta)\n",
    "BoB = B_zeta**2\n",
    "z = np.load(z_path) #[0:B_zeta.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p is the number of beta coefficients in the last hidden layer\n",
    "p = B_zeta.shape[1]\n",
    "\n",
    "# Lambda is a diagonal matrix of dimension p\n",
    "Lambda = np.random.rand(p,)\n",
    "\n",
    "seed(679305)\n",
    "tau_start = 0.01\n",
    "\n",
    "# Set iteration counter to 0\n",
    "t = 0\n",
    "\n",
    "theta = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(43736, 10)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "B_zeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = B_zeta.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[ S(\\boldsymbol{x}, \\boldsymbol{\\theta}) = diag(s_1,...,s_n) \\\\]\n",
    "\n",
    "with $ s_i = (1+ \\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^TP(\\boldsymbol{\\theta})^{-1}\\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^{-\\frac{1}{2}}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S(x, theta) is of dimension n x n\n",
    "dS2, ddS2, S2, S = hlp.generate_dS2_ddS2_S2_S(Lambda, BoB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialize $\\lambda = \\lambda^{(0)} = (\\mu^{(0)},B^{(0)},d^{(0)}), \\, t = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m is number of variational parameters, which is \n",
    "# 2p (for each lambda_j and each beta_j)\n",
    "# plus the variational parameter for the prior on lambda\n",
    "m = 2*p + 1\n",
    "\n",
    "# number of factors in the factored covariance representation\n",
    "k = m - 2\n",
    "\n",
    "mu_t = np.array([random() for i in range(0,m)]).reshape(m,1)\n",
    "# B is a lower triangle m x k matrix and is the first component of the \n",
    "# covariance matrix\n",
    "B_t = np.tril(np.random.rand(m,k))\n",
    "while not np.linalg.matrix_rank(B_t) == k:\n",
    "    B_t = np.tril(np.random.rand(m,k))\n",
    "\n",
    "# D is a diagonal matrix of dimension m x m and is the second component of the \n",
    "# covariance matrix\n",
    "D_t = np.diag(np.random.rand(m,))\n",
    "d_t = np.diag(D_t).reshape(m,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate $(\\epsilon^{(t)}, z^{(t)}) \\sim \\mathcal{N}(0,I) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_epsilon = np.repeat(0, m)\n",
    "mean_z = np.repeat(0, k)\n",
    "\n",
    "var_epsilon = np.diag(np.repeat(1,m))\n",
    "var_z = np.diag(np.repeat(1,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adadelta\n",
    "decay_rate = 0.95\n",
    "constant = 1e-7\n",
    "E_g2_t_1 = 0\n",
    "E_delta_x_2_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_g2_t_1_mu = np.repeat(0, len(mu_t))\n",
    "E_delta_x_2_1_mu = np.repeat(0, len(mu_t))\n",
    "E_g2_t_1_B = np.zeros(B_t.shape)\n",
    "E_delta_x_2_1_B = np.zeros(B_t.shape)\n",
    "E_g2_t_1_d = np.repeat(0, len(d_t)).reshape(m,1)\n",
    "E_delta_x_2_1_d = np.repeat(0, len(d_t)).reshape(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adadelta_change(gradient, E_g2_t_1, E_delta_x_2_1, decay_rate = 0.99, constant = 10e-6):\n",
    "    # expected squared gradient for next iteration\n",
    "    E_g2_t = decay_rate*E_g2_t_1 + (1 - decay_rate)*(gradient**2)\n",
    "    # update for parameter\n",
    "    # should there be a minus or plus here ?????\n",
    "    delta_x =  (np.sqrt(E_delta_x_2_1 + constant)/np.sqrt(E_g2_t + constant))*gradient\n",
    "    # expected update for next iteration\n",
    "    E_delta_x_2 = decay_rate*E_delta_x_2_1 + (1 - decay_rate)*(delta_x**2)\n",
    "    return(delta_x, E_g2_t, E_delta_x_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  1%|          | 188/30000 [08:25<22:28:01,  2.71s/it]"
     ]
    }
   ],
   "source": [
    "#lower_bounds = []\n",
    "#all_varthetas = []\n",
    "#mu_ts = []\n",
    "#d_ts = []\n",
    "#B_ts = []\n",
    "#Lambda_ts = []\n",
    "#log_tau_ts = []\n",
    "t = 0\n",
    "iterations = 30000\n",
    "for i in tqdm(range(iterations)):\n",
    "    \n",
    "    # 1. Generate epsilon_t and z_t\n",
    "    z_t = hlp.generate_z(mean_z,var_z)\n",
    "    epsilon_t = hlp.generate_epsilon(mean_epsilon, var_epsilon)\n",
    "    \n",
    "    # 2. Draw from vartheta, what we generate are log values\n",
    "    # of lambda and tau -> have to transform them back to use them\n",
    "    vartheta_t = mu_t + B_t.dot(z_t) + (d_t*epsilon_t)\n",
    "    \n",
    "    beta_t = vartheta_t[0:p].reshape(p,)\n",
    "    betaBt_t = beta_t.dot(B_zeta.T)\n",
    "    \n",
    "    # 3. Compute gradient of beta, lambda_j, and tau\n",
    "    gradient_h_t = hlp.Delta_theta(vartheta_t, B_zeta, n, z, p, tBB, betaBt_t, BoB)\n",
    "    \n",
    "    \n",
    "    # Compute inverse with Woodbury formula.\n",
    "    inv = np.linalg.inv(D_t.dot(D_t))\n",
    "    inv2 = np.linalg.inv(np.identity(k) + B_t.T.dot(inv).dot(B_t))\n",
    "    BBD_inv = inv - multi_dot([inv, B_t, inv2, B_t.T, inv])\n",
    "    \n",
    "    # Compute gradients for the variational parameters mu, B, D\n",
    "    Delta_mu = hlp.Delta_mu(gradient_h_t, BBD_inv, z_t, d_t, epsilon_t, B_t)\n",
    "    Delta_B = hlp.Delta_B(B_zeta,n,z, p, B_t, gradient_h_t, z_t, D_t, d_t, epsilon_t, BBD_inv)\n",
    "    Delta_D = hlp.Delta_D(gradient_h_t, epsilon_t,D_t, d_t,p, BBD_inv)\n",
    "    \n",
    "    # 4. Adadelta Updates\n",
    "    update_mu, E_g2_t_1_mu, E_delta_x_2_1_mu = adadelta_change(Delta_mu, E_g2_t_1_mu, E_delta_x_2_1_mu, decay_rate = decay_rate, constant = constant)\n",
    "    update_B, E_g2_t_1_B, E_delta_x_2_1_B  = adadelta_change(Delta_B, E_g2_t_1_B, E_delta_x_2_1_B, decay_rate = decay_rate, constant = constant)\n",
    "    update_d, E_g2_t_1_d, E_delta_x_2_1_d = adadelta_change(Delta_D, E_g2_t_1_d, E_delta_x_2_1_d, decay_rate = decay_rate, constant = constant)\n",
    "    \n",
    "    # Update variables\n",
    "    '''rho = 0.9\n",
    "    mu_t = mu_t + rho*Delta_mu.reshape(m,1)\n",
    "    B_t = B_t + rho*Delta_B\n",
    "    B_t *= np.tri(*B_t.shape)\n",
    "    d_t = (d_t + rho*Delta_D)\n",
    "    D_t = np.diag(d_t.reshape(m,))'''\n",
    "    mu_t = mu_t + update_mu.reshape(m,1)\n",
    "    B_t = B_t + update_B\n",
    "    # set upper triangular elements to 0\n",
    "    B_t *= np.tri(*B_t.shape)\n",
    "    d_t = (d_t + update_d)\n",
    "    D_t = np.diag(d_t.reshape(m,))\n",
    "    \n",
    "    vartheta_t = mu_t + B_t.dot(z_t) + (d_t*epsilon_t)\n",
    "    vartheta_t_transf = vartheta_t.copy()\n",
    "    \n",
    "    # 5. compute stopping criterion\n",
    "    beta_t = vartheta_t_transf[0:p].reshape(p,)\n",
    "    Lambda_t = vartheta_t_transf[p:2*p].reshape(p,)\n",
    "    log_tau_t = vartheta_t_transf[2*p]\n",
    "    betaBt_t = beta_t.dot(B_zeta.T) \n",
    "    \n",
    "    dS2, ddS2, S2, S = hlp.generate_dS2_ddS2_S2_S(Lambda_t, BoB)\n",
    "    \n",
    "    # Lower bound L(lambda) = E[log(L_lambda - q_lambda]\n",
    "    log_h_t = hlp.log_density(S, B_zeta, beta_t, Lambda_t, log_tau_t, z, p)\n",
    "    log_q_lambda_t = np.log(hlp.multivariate_normal(vartheta_t, m, mu_t, (B_t.dot(B_t.T) + D_t**2)))\n",
    "    \n",
    "    # evidence lower bound\n",
    "    L_lambda = log_h_t - log_q_lambda_t\n",
    "    log_tau_ts.append(log_tau_t)\n",
    "    Lambda_ts.append(Lambda_t)\n",
    "    lower_bounds.append(L_lambda.item())\n",
    "    all_varthetas.append(vartheta_t)\n",
    "    \n",
    "    # increase time count\n",
    "    t = t+1\n",
    "    \n",
    "    # can also set lambda as the value over the last 10 steps\n",
    "    mu_ts.append(mu_t)\n",
    "    d_ts.append(d_t)\n",
    "    B_ts.append(B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(lower_bounds)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(all_varthetas).reshape(8019, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.mean(np.array(all_varthetas).reshape(24026, 11)[:, 0:p], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_varthetas).reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/lower_bounds_delete.npy', lower_bounds)\n",
    "#np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/vartheta_delete.npy', np.array(all_varthetas))\n",
    "np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/mu_ts_delete.npy', mu_ts)\n",
    "np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/d_ts_delete.npy', d_ts)\n",
    "np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/B_ts_delete.npy', B_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check convergence graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,t), lower_bounds, linewidth=0.1)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lower_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(beta, beta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save $\\vartheta$ over last 10% of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_10_percent = iterations*0.01\n",
    "vartheta_hat = mean(all_varthetas[last_10_percent:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../../../data/commaai/va/unfiltered_gaussian_resampled/Ridgevartheta_hat.csv', vartheta_hat, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds = np.load('../../../../data/commaai/va/filtered_gaussian_resampled/Ridge/lower_bounds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lower_bounds[0:10000])\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
