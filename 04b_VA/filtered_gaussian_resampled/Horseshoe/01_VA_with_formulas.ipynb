{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import helpers as hlp\n",
    "import math\n",
    "from random import random, seed\n",
    "from numpy.linalg import multi_dot\n",
    "from scipy.stats import multivariate_normal\n",
    "import matplotlib.pyplot as plt \n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<script type=\"text/javascript\"\n",
    "        src=\"https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.0/MathJax.js?config=TeX-AMS_CHTML\"></script>\n",
    "\n",
    "## Model\n",
    "Linear model\n",
    "\\\\[ \\tilde{\\boldsymbol{Z}} = B_{\\boldsymbol{\\zeta}}(\\boldsymbol{x})\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon} \\, \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2I) \\\\]\n",
    "\n",
    "and the transformed target variables follow a conditional normal distribution\n",
    "\n",
    "\\\\[ \\boldsymbol{Z} | \\boldsymbol{x}, \\sigma^2, \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{0}, R(\\boldsymbol{x}, \\boldsymbol{\\theta})^T) \\\\]\n",
    "with $ R(\\boldsymbol{x}, \\boldsymbol{\\theta}) = S(\\boldsymbol{x}, \\boldsymbol{\\theta})(I - B\\Omega B^T)^{-1}S(\\boldsymbol{x}, \\boldsymbol{\\theta})^T $\n",
    "\n",
    "and each Z_i has a marginal standard-normal distribution.\n",
    "\n",
    "The coefficient vector beta follows a conditional normal distribution\n",
    "\n",
    "\\\\[ \\boldsymbol{\\beta} | \\boldsymbol{x}, \\sigma^2, \\boldsymbol{\\theta} \\sim \\mathcal{N}(\\boldsymbol{0}, \\sigma^2 P(\\boldsymbol{\\theta})^{-1}) \\\\]\n",
    "\n",
    "\n",
    "## Prior on copula parameters\n",
    "\n",
    "Horseshoe prior on coefficients\n",
    "\\\\[\\beta_j| \\lambda_j \\sim \\mathcal{N}(0,\\lambda_j^2) \\\\]\n",
    "with $\\pi_0(\\lambda_j | \\tau) = C^{+}(0,\\tau) $ and $ \\pi_0(\\tau) = C^{+}(0,1)$, where $C^{+}$ is the half-Cauchy distribution\n",
    "\n",
    "Then the vector of copula parameters is\n",
    "\\\\[\\boldsymbol{\\theta} = \\{ \\boldsymbol{\\lambda}, \\tau \\} \\\\]\n",
    "with \n",
    "\\\\[ \\boldsymbol{\\lambda} = (\\lambda_1,...\\lambda_p)^T \\\\]\n",
    "\n",
    "\\begin{equation}\n",
    "   P(\\boldsymbol{\\theta}) = diag(\\lambda_1^2,...\\lambda_p^2)^{-1}\n",
    "\\end{equation}\n",
    "and \n",
    "\\\\[ R(\\boldsymbol{x}, \\boldsymbol{\\theta}) = S(\\boldsymbol{x}, \\boldsymbol{\\theta}(I + B \\mathrm{diag}(\\lambda_1, ... \\lambda_p)^2 B ^T)S(\\boldsymbol{x}, \\boldsymbol{\\theta}) \\\\]\n",
    "\n",
    "\n",
    " - > so is P(theta) then just diag(phi_i)?\n",
    "Distribution of targets y\n",
    "\n",
    "\\\\[ p(\\boldsymbol{y}| \\boldsymbol{x}, \\boldsymbol{\\beta}, \\boldsymbol{\\theta}) = \\phi_n(\\boldsymbol{z};S(\\boldsymbol{x}, \\boldsymbol{\\theta})B_{\\boldsymbol{\\zeta}}\\boldsymbol{\\beta}, S(\\boldsymbol{x}, \\boldsymbol{\\theta})^2) \\prod_{i=1}^n \\frac{p_Y(y_i)}{\\phi_1(z_i)}, \\\\]\n",
    "with\n",
    "\n",
    "\\\\[ S(\\boldsymbol{x}, \\boldsymbol{\\theta}) = diag(s_1,...,s_n) \\\\]\n",
    "\n",
    "with $ s_i = (1+ \\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^TP(\\boldsymbol{\\theta})^{-1}\\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^{-\\frac{1}{2}}) $\n",
    "\n",
    "and specifically for the horseshoe prior case:\n",
    "\\\\[s_i = (1+ \\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^T P(\\boldsymbol{\\theta})^{-1}\\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^{-\\frac{1}{2}} \\\\]\n",
    "\n",
    "\n",
    "Now we want to optimize the ELBO which is given by\n",
    "\\\\[ \\mathcal{L}(\\lambda) = \\mathbb{E}_q[\\log h(\\vartheta) - \\log q_{\\lambda}(\\vartheta) ] \\\\]\n",
    "\n",
    "where $\\vartheta = \\{\\beta, \\theta \\}$ and $h(\\vartheta) = p(\\vartheta)p(y|\\vartheta)$.\n",
    "We want to estimate the augmented posteriors $\\beta, \\theta | \\boldsymbol{y}$\n",
    "\n",
    "\n",
    "## VA with factor covariance structure\n",
    "\n",
    "Choose an approximating family $ q_{\\lambda}(\\vartheta) $, in our case this is \n",
    "\\begin{equation}\n",
    "q_{\\lambda}(\\vartheta) = \\mathcal{N}(\\boldsymbol{\\mu}, BB^T + D^2),\n",
    "\\end{equation}\n",
    "with $d = \\{d_1,...d_m \\}$. The dimension of this distribution is $m$ and in the case of the horseshoe prior this is # of betas + 1 (tau) $= p+1$. The dimension of $B$ is $m \\times k$, where $k$ specifies the number of factors. To make computation easier $k$ should be much smaller than $m$. This implies that we can represent the dependency structure in the covariance matrix with a smaller number of latent variables, thus facilitating faster computation.\n",
    "\n",
    "How can we draw from this distribution?\n",
    "- first draw $(\\boldsymbol{z}, \\boldsymbol{\\epsilon}) \\sim \\mathcal{N}(0,I)$, where $\\boldsymbol{z}$ is of dimension $k \\times 1 $ and $\\boldsymbol{\\epsilon}$ is $m \\times 1$\n",
    "- then calculate $\\vartheta = \\boldsymbol{\\mu} + B\\boldsymbol{z} + d \\circ \\epsilon$, where $\\circ$ denotes the Hadamard product, i.e. the element by element multiplication of two vectors.\n",
    "\n",
    "By applying the reparametrization trick we can now change the  expectation with regard to $q_{\\lambda}(\\theta)$, namely $\\mathbb{E}_q$ to an expectation with regard to standard normal density of $z, \\epsilon$, which is denoted as $f(z, \\epsilon)$, which leads to the expectation $\\mathbb{E}_f$.\n",
    "Instead of evaluating the first time of the ELBO at $\\theta$, we evaluate it at the reparametarized $\\theta = \\mu + Bz + d \\circ \\epsilon$.\n",
    "The expectation with regard to $f$, $\\mathbb{E}_f$, can be estimated unbiasedly by generating one or more samples from $f$.\n",
    "\n",
    "Calculating the gradients delivers:\n",
    "- gradient w.r.t $\\mu$, i.e. mean of variational parameters $\\nabla_{\\mu} \\mathcal{L}(\\lambda) = \\mathbb{E}_f[\\nabla_{\\vartheta} \\log h(\\mu + Bz + d \\circ \\epsilon)]$\n",
    "- gradient w.r.t. $B$, i.e. first component of covariance matrix of variational parameters $\\nabla_B \\mathcal{L}(\\lambda) = \\mathbb{E}_f[ \\nabla_{\\vartheta} \\log h(\\mu + Bz + d \\circ \\epsilon)z^T + (BB^T + D^2)^{-1}(Bz+d \\circ \\epsilon)z^T]$\n",
    "- gradient w.r.t. $D = \\mathrm{diag}(d_1,...,d_n)$, i.e. the second component of covariance matrix of variational parameters $\\nabla_d \\mathcal{L}(\\lambda) = \\mathbb{E}_f[\\mathrm{diag}(\\nabla_{\\vartheta} \\log h(\\mu + Bz + d \\circ \\epsilon) \\epsilon^T + (BB^T + D^2)^{-1}(Bz + d \\circ \\epsilon) \\epsilon^T] $\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Step 0: Initialize $\\lambda = \\lambda^{(0)} = (\\mu^{(0)}, B^{(0)}, d^{(0)})$, $t = 0$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load variables from training DNN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "extracted_coefficients_path = '../../../../data/commaai/extracted_coefficients/20201027_filtered_gaussian_resampled/'\n",
    "B_zeta_path = str(extracted_coefficients_path + 'Bzeta/B_zeta.npy')\n",
    "beta_path = str(extracted_coefficients_path + 'beta/beta.csv')\n",
    "z_path = str(extracted_coefficients_path + 'Bzeta/tr_labels.npy')\n",
    "\n",
    "beta = np.genfromtxt(beta_path, delimiter=',')\n",
    "# B_zeta is a n x q matrix\n",
    "B_zeta = np.load(B_zeta_path)\n",
    "B_zeta = B_zeta.reshape(B_zeta.shape[0], beta.shape[0])\n",
    "tBB = B_zeta.T.dot(B_zeta)\n",
    "BoB = B_zeta**2\n",
    "z = np.load(z_path) #[0:B_zeta.shape[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# p is the number of beta coefficients in the last hidden layer\n",
    "p = B_zeta.shape[1]\n",
    "\n",
    "# Lambda is a diagonal matrix of dimension p\n",
    "Lambda = np.random.rand(p,)\n",
    "\n",
    "seed(679305)\n",
    "tau_start = 0.01\n",
    "\n",
    "# Set iteration counter to 0\n",
    "t = 0\n",
    "\n",
    "theta = 2.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_zeta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = B_zeta.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\\\\[ S(\\boldsymbol{x}, \\boldsymbol{\\theta}) = diag(s_1,...,s_n) \\\\]\n",
    "\n",
    "with $ s_i = (1+ \\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^TP(\\boldsymbol{\\theta})^{-1}\\psi_{\\boldsymbol{\\zeta}}(\\boldsymbol{x}_i)^{-\\frac{1}{2}}) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# S(x, theta) is of dimension n x n\n",
    "dS2, ddS2, S2, S = hlp.generate_dS2_ddS2_S2_S(Lambda, BoB)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cycle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 0. Initialize $\\lambda = \\lambda^{(0)} = (\\mu^{(0)},B^{(0)},d^{(0)}), \\, t = 0$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# m is number of variational parameters, which is \n",
    "# 2p (for each lambda_j and each beta_j)\n",
    "# plus the variational parameter for the prior on lambda\n",
    "m = 2*p + 1\n",
    "\n",
    "# number of factors in the factored covariance representation\n",
    "k = m - 2\n",
    "\n",
    "mu_t = np.array([random() for i in range(0,m)]).reshape(m,1)\n",
    "# B is a lower triangle m x k matrix and is the first component of the \n",
    "# covariance matrix\n",
    "B_t = np.tril(np.random.rand(m,k))\n",
    "while not np.linalg.matrix_rank(B_t) == k:\n",
    "    B_t = np.tril(np.random.rand(m,k))\n",
    "\n",
    "# D is a diagonal matrix of dimension m x m and is the second component of the \n",
    "# covariance matrix\n",
    "D_t = np.diag(np.random.rand(m,))\n",
    "d_t = np.diag(D_t).reshape(m,1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Generate $(\\epsilon^{(t)}, z^{(t)}) \\sim \\mathcal{N}(0,I) $"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mean_epsilon = np.repeat(0, m)\n",
    "mean_z = np.repeat(0, k)\n",
    "\n",
    "var_epsilon = np.diag(np.repeat(1,m))\n",
    "var_z = np.diag(np.repeat(1,k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## Adadelta\n",
    "decay_rate = 0.95\n",
    "constant = 1e-7\n",
    "E_g2_t_1 = 0\n",
    "E_delta_x_2_1 = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "E_g2_t_1_mu = np.repeat(0, len(mu_t))\n",
    "E_delta_x_2_1_mu = np.repeat(0, len(mu_t))\n",
    "E_g2_t_1_B = np.zeros(B_t.shape)\n",
    "E_delta_x_2_1_B = np.zeros(B_t.shape)\n",
    "E_g2_t_1_d = np.repeat(0, len(d_t)).reshape(m,1)\n",
    "E_delta_x_2_1_d = np.repeat(0, len(d_t)).reshape(m,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def adadelta_change(gradient, E_g2_t_1, E_delta_x_2_1, decay_rate = 0.99, constant = 10e-6):\n",
    "    # expected squared gradient for next iteration\n",
    "    E_g2_t = decay_rate*E_g2_t_1 + (1 - decay_rate)*(gradient**2)\n",
    "    # update for parameter\n",
    "    # should there be a minus or plus here ?????\n",
    "    delta_x =  (np.sqrt(E_delta_x_2_1 + constant)/np.sqrt(E_g2_t + constant))*gradient\n",
    "    # expected update for next iteration\n",
    "    E_delta_x_2 = decay_rate*E_delta_x_2_1 + (1 - decay_rate)*(delta_x**2)\n",
    "    return(delta_x, E_g2_t, E_delta_x_2 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#lower_bounds = []\n",
    "#all_varthetas = []\n",
    "#mu_ts = []\n",
    "#d_ts = []\n",
    "#B_ts = []\n",
    "#Lambda_ts = []\n",
    "#log_tau_ts = []\n",
    "t = 0\n",
    "iterations = 30000\n",
    "for i in tqdm(range(iterations)):\n",
    "    \n",
    "    # 1. Generate epsilon_t and z_t\n",
    "    z_t = hlp.generate_z(mean_z,var_z)\n",
    "    epsilon_t = hlp.generate_epsilon(mean_epsilon, var_epsilon)\n",
    "    \n",
    "    # 2. Draw from vartheta, what we generate are log values\n",
    "    # of lambda and tau -> have to transform them back to use them\n",
    "    vartheta_t = mu_t + B_t.dot(z_t) + (d_t*epsilon_t)\n",
    "    \n",
    "    beta_t = vartheta_t[0:p].reshape(p,)\n",
    "    betaBt_t = beta_t.dot(B_zeta.T)\n",
    "    \n",
    "    # 3. Compute gradient of beta, lambda_j, and tau\n",
    "    gradient_h_t = hlp.Delta_theta(vartheta_t, B_zeta, n, z, p, tBB, betaBt_t, BoB)\n",
    "    \n",
    "    \n",
    "    # Compute inverse with Woodbury formula.\n",
    "    inv = np.linalg.inv(D_t.dot(D_t))\n",
    "    inv2 = np.linalg.inv(np.identity(k) + B_t.T.dot(inv).dot(B_t))\n",
    "    BBD_inv = inv - multi_dot([inv, B_t, inv2, B_t.T, inv])\n",
    "    \n",
    "    # Compute gradients for the variational parameters mu, B, D\n",
    "    Delta_mu = hlp.Delta_mu(gradient_h_t, BBD_inv, z_t, d_t, epsilon_t, B_t)\n",
    "    Delta_B = hlp.Delta_B(B_zeta,n,z, p, B_t, gradient_h_t, z_t, D_t, d_t, epsilon_t, BBD_inv)\n",
    "    Delta_D = hlp.Delta_D(gradient_h_t, epsilon_t,D_t, d_t,p, BBD_inv)\n",
    "    \n",
    "    # 4. Adadelta Updates\n",
    "    update_mu, E_g2_t_1_mu, E_delta_x_2_1_mu = adadelta_change(Delta_mu, E_g2_t_1_mu, E_delta_x_2_1_mu, decay_rate = decay_rate, constant = constant)\n",
    "    update_B, E_g2_t_1_B, E_delta_x_2_1_B  = adadelta_change(Delta_B, E_g2_t_1_B, E_delta_x_2_1_B, decay_rate = decay_rate, constant = constant)\n",
    "    update_d, E_g2_t_1_d, E_delta_x_2_1_d = adadelta_change(Delta_D, E_g2_t_1_d, E_delta_x_2_1_d, decay_rate = decay_rate, constant = constant)\n",
    "    \n",
    "    # Update variables\n",
    "    '''rho = 0.9\n",
    "    mu_t = mu_t + rho*Delta_mu.reshape(m,1)\n",
    "    B_t = B_t + rho*Delta_B\n",
    "    B_t *= np.tri(*B_t.shape)\n",
    "    d_t = (d_t + rho*Delta_D)\n",
    "    D_t = np.diag(d_t.reshape(m,))'''\n",
    "    mu_t = mu_t + update_mu.reshape(m,1)\n",
    "    B_t = B_t + update_B\n",
    "    # set upper triangular elements to 0\n",
    "    B_t *= np.tri(*B_t.shape)\n",
    "    d_t = (d_t + update_d)\n",
    "    D_t = np.diag(d_t.reshape(m,))\n",
    "    \n",
    "    vartheta_t = mu_t + B_t.dot(z_t) + (d_t*epsilon_t)\n",
    "    vartheta_t_transf = vartheta_t.copy()\n",
    "    \n",
    "    # 5. compute stopping criterion\n",
    "    beta_t = vartheta_t_transf[0:p].reshape(p,)\n",
    "    Lambda_t = vartheta_t_transf[p:2*p].reshape(p,)\n",
    "    log_tau_t = vartheta_t_transf[2*p]\n",
    "    betaBt_t = beta_t.dot(B_zeta.T) \n",
    "    \n",
    "    dS2, ddS2, S2, S = hlp.generate_dS2_ddS2_S2_S(Lambda_t, BoB)\n",
    "    \n",
    "    # Lower bound L(lambda) = E[log(L_lambda - q_lambda]\n",
    "    log_h_t = hlp.log_density(S, B_zeta, beta_t, Lambda_t, log_tau_t, z, p)\n",
    "    log_q_lambda_t = np.log(hlp.multivariate_normal(vartheta_t, m, mu_t, (B_t.dot(B_t.T) + D_t**2)))\n",
    "    \n",
    "    # evidence lower bound\n",
    "    L_lambda = log_h_t - log_q_lambda_t\n",
    "    log_tau_ts.append(log_tau_t)\n",
    "    Lambda_ts.append(Lambda_t)\n",
    "    lower_bounds.append(L_lambda.item())\n",
    "    all_varthetas.append(vartheta_t)\n",
    "    \n",
    "    # increase time count\n",
    "    t = t+1\n",
    "    \n",
    "    # can also set lambda as the value over the last 10 steps\n",
    "    mu_ts.append(mu_t)\n",
    "    d_ts.append(d_t)\n",
    "    B_ts.append(B_t)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(lower_bounds)\n",
    "#plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(np.array(all_varthetas).reshape(8019, 21))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.mean(np.array(all_varthetas).reshape(24026, 11)[:, 0:p], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.array(all_varthetas).reshape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/lower_bounds_delete.npy', lower_bounds)\n",
    "#np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/vartheta_delete.npy', np.array(all_varthetas))\n",
    "np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/mu_ts_delete.npy', mu_ts)\n",
    "np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/d_ts_delete.npy', d_ts)\n",
    "np.save('../../data/commaai/va/filtered_gaussian_resampled/Ridge/B_ts_delete.npy', B_ts)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check convergence graphically"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(range(0,t), lower_bounds, linewidth=0.1)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(lower_bounds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(beta, beta_t)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save $\\vartheta$ over last 10% of runs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_10_percent = iterations*0.01\n",
    "vartheta_hat = mean(all_varthetas[last_10_percent:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.savetxt('../../../data/commaai/va/unfiltered_gaussian_resampled/Ridgevartheta_hat.csv', vartheta_hat, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds = np.load('../../../../data/commaai/va/filtered_gaussian_resampled/Ridge/lower_bounds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(lower_bounds[0:10000])\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "lower_bounds = np.load('../../../../data/commaai/va/filtered_gaussian_resampled/Horseshoe/lower_bounds.npy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure()\n",
    "ax = fig.add_subplot()\n",
    "ax.plot(lower_bounds)\n",
    "plt.yscale('symlog')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
