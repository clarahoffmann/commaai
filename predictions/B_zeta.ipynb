{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load packages\n",
    "import os\n",
    "import glob\n",
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "from tensorflow import keras\n",
    "from keras import backend\n",
    "from keras.layers import Dense, Conv2D, MaxPooling2D, Dropout, Flatten, BatchNormalization\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# path of model checkpoints\n",
    "checkpoint_path = '../../data/models/20200928_nvidia_ai/'\n",
    "extracted_coefficients_directory = '../../data/models/extracted_coefficients/20200928_nvidia_ai/'\n",
    "shard_path = '../../data/commaai/train_files_from_bag_test'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "shard_files = glob.glob(os.path.join(shard_path, \"*.tfrecords\")) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get $\\beta$\n",
    "0. Build model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# build model\n",
    "Input = tf.keras.layers.Input(shape=(66, 200, 3,), name='image')\n",
    "x = Conv2D(24, kernel_size=(5, 5), activation='relu', strides=(2, 2))(Input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(36, kernel_size=(5, 5), activation='relu', strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(48, kernel_size=(5, 5), activation='relu', strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1164)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(100)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50)(x) \n",
    "x = Dense(10)(x)\n",
    "Output = Dense(1, name = 'output_layer')(x)\n",
    "\n",
    "keras_model = tf.keras.models.Model(\n",
    "      inputs = [Input], outputs = [Output])\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "keras_model.load_weights(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "adam_optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "# old\n",
    "#keras.optimizers.Adadelta(learning_rate = 0.001, rho = 0.95, epsilon = 1e-07, name = 'Adadelta')\n",
    "keras_model.compile(\n",
    "    loss = rmse,\n",
    "    optimizer = adam_optimizer,\n",
    "    metrics=[rmse, 'mse', 'mae'])\n",
    "\n",
    "keras_estimator = tf.keras.estimator.model_to_estimator(\n",
    "      keras_model=keras_model)\n",
    "# to inspect weights:\n",
    "#i = 0 \n",
    "#for layer in keras_model.layers: \n",
    "#    i += 1\n",
    "#    if i == 16:\n",
    "#        print(layer.get_config(), layer.get_weights())\n",
    "\n",
    "# get list of all variables in checkpoint file\n",
    "# tf.train.list_variables(tf.train.latest_checkpoint(checkpoint_path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for layer in keras_model.layers: \n",
    "    i += 1\n",
    "    if i == 18:\n",
    "        beta = layer.get_weights()\n",
    "        print(layer.get_config()) #, layer.get_weights()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# last element of beta is bias, exclude this \n",
    "# since copulas are location free -> beta_0 = 0\n",
    "beta_coeff = beta[0]\n",
    "np.savetxt(str(extracted_coefficients_directory +\"beta.csv\"), beta_coeff, delimiter=\",\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get model for $B_{\\zeta}$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Input = tf.keras.layers.Input(shape=(66, 200, 3,), name='image')\n",
    "x = Conv2D(24, kernel_size=(5, 5), activation='relu', strides=(2, 2))(Input)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(36, kernel_size=(5, 5), activation='relu', strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(48, kernel_size=(5, 5), activation='relu', strides=(2, 2))(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "x = BatchNormalization()(x)\n",
    "x = Conv2D(64, kernel_size=(3, 3), activation='relu')(x)\n",
    "#x = BatchNormalization()(x)\n",
    "x = Flatten()(x)\n",
    "x = Dense(1164)(x)\n",
    "x = Dropout(0.5)(x)\n",
    "x = Dense(100)(x)\n",
    "x = Dropout(0.2)(x)\n",
    "x = Dense(50)(x) \n",
    "Output = Dense(10)(x)\n",
    "\n",
    "B_zeta = tf.keras.models.Model(\n",
    "      inputs = [Input], outputs = [Output])\n",
    "\n",
    "B_zeta.load_weights(tf.train.latest_checkpoint(checkpoint_path))\n",
    "\n",
    "def rmse(y_true, y_pred):\n",
    "\treturn backend.sqrt(backend.mean(backend.square(y_pred - y_true), axis=-1))\n",
    "\n",
    "adam_optimizer = keras.optimizers.Adam(learning_rate=0.0005)\n",
    "# old\n",
    "#keras.optimizers.Adadelta(learning_rate = 0.001, rho = 0.95, epsilon = 1e-07, name = 'Adadelta')\n",
    "B_zeta.compile(\n",
    "    loss = rmse,\n",
    "    optimizer = adam_optimizer,\n",
    "    metrics=[rmse, 'mse', 'mae'])\n",
    "\n",
    "#B_zeta_estimator = tf.keras.estimator.model_to_estimator(\n",
    "#      keras_model=B_zeta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "get training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# maximum number of elements in shard is 240\n",
    "bs = 240\n",
    "def imgs_input_fn(filenames, perform_shuffle = False, repeat_count = 1, batch_size = bs): \n",
    "    \n",
    "    # reads in single training example and returns it in a format that the estimator can\n",
    "    # use\n",
    "    def _parse_function(proto):\n",
    "        # define your tfrecord again. Remember that you saved your image as a string.\n",
    "        keys_to_features = {'image': tf.io.FixedLenFeature([], tf.string),\n",
    "                            \"label\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                            'rows': tf.io.FixedLenFeature([], tf.int64),\n",
    "                            'cols': tf.io.FixedLenFeature([], tf.int64),\n",
    "                            'depth': tf.io.FixedLenFeature([], tf.int64),\n",
    "                            \"tr_label\": tf.io.FixedLenFeature([], tf.float32),\n",
    "                           }\n",
    "\n",
    "        # Load one example\n",
    "        parsed_example = tf.io.parse_single_example(proto, keys_to_features)\n",
    "\n",
    "        image_shape = tf.stack([131 , 174, 3])\n",
    "        image_raw = parsed_example['image']\n",
    "\n",
    "        label = tf.cast(parsed_example['label'], tf.float32)\n",
    "        tr_label = tf.cast(parsed_example['tr_label'], tf.float32)\n",
    "        image = tf.io.decode_raw(image_raw, tf.uint8)\n",
    "        image = tf.cast(image, tf.float32)\n",
    "\n",
    "        image = tf.reshape(image, image_shape)\n",
    "        image = tf.image.resize(image[33:99,37:137, :], [66,200])\n",
    "        image = image/255\n",
    "        \n",
    "        return {'image':image}, tr_label, label\n",
    "    \n",
    "    dataset = tf.data.TFRecordDataset(filenames = filenames)\n",
    "    dataset = dataset.map(_parse_function)\n",
    "    if perform_shuffle:\n",
    "        # Randomizes input using a window of 256 elements (read into memory)\n",
    "        dataset = dataset.shuffle(buffer_size=256)\n",
    "    dataset = dataset.repeat(repeat_count)  # Repeats dataset this # times\n",
    "    dataset = dataset.batch(batch_size)  # Batch size to use\n",
    "    iterator = tf.compat.v1.data.make_one_shot_iterator(dataset)\n",
    "    batch_features, batch_tr_labels, batch_labels = iterator.get_next()\n",
    "    \n",
    "    return batch_features, batch_tr_labels, batch_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "shardzero = shard_files[0]\n",
    "images, tr_labels, labels = imgs_input_fn(shardzero)\n",
    "tr_labels = np.array(tr_labels)\n",
    "labels = np.array(labels)\n",
    "df = pd.DataFrame({'tr_label': tr_labels, 'label': labels})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tr_label</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.418915</td>\n",
       "      <td>-1.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2.202471</td>\n",
       "      <td>13.100000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1.191695</td>\n",
       "      <td>-23.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2.546087</td>\n",
       "      <td>23.600000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1.233022</td>\n",
       "      <td>32.799999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>100</th>\n",
       "      <td>-2.695096</td>\n",
       "      <td>-28.700001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>101</th>\n",
       "      <td>1.567552</td>\n",
       "      <td>33.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>102</th>\n",
       "      <td>-2.752856</td>\n",
       "      <td>-33.299999</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>103</th>\n",
       "      <td>-inf</td>\n",
       "      <td>-40.500000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>104</th>\n",
       "      <td>0.935097</td>\n",
       "      <td>50.700001</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>105 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     tr_label      label\n",
       "0   -0.418915  -1.100000\n",
       "1    2.202471  13.100000\n",
       "2    1.191695 -23.600000\n",
       "3    2.546087  23.600000\n",
       "4    1.233022  32.799999\n",
       "..        ...        ...\n",
       "100 -2.695096 -28.700001\n",
       "101  1.567552  33.299999\n",
       "102 -2.752856 -33.299999\n",
       "103      -inf -40.500000\n",
       "104  0.935097  50.700001\n",
       "\n",
       "[105 rows x 2 columns]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-dee8a1434975>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtr_labels\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'nan'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfloat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'inf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/usr/local/lib/python3.8/dist-packages/tensorflow/python/framework/ops.py\u001b[0m in \u001b[0;36m__bool__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    982\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    983\u001b[0m   \u001b[0;32mdef\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 984\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0mbool\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_numpy\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    985\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    986\u001b[0m   \u001b[0m__nonzero__\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m__bool__\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The truth value of an array with more than one element is ambiguous. Use a.any() or a.all()"
     ]
    }
   ],
   "source": [
    "tr_labels in [-float('inf'), float('nan'), float('inf')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "shardzero = shard_files[0]\n",
    "images, labels = imgs_input_fn(shardzero)\n",
    "images = np.array(images['image'])\n",
    "labels = np.array(labels)\n",
    "all_images = images\n",
    "all_labels = labels\n",
    "for shard in tqdm(shard_files[1:]):\n",
    "    try:\n",
    "        images, labels = imgs_input_fn(shard)\n",
    "        images = np.array(images['image'])\n",
    "        labels = np.array(labels)\n",
    "        all_images = np.append(all_images, images, axis = 0)\n",
    "        all_labels = np.append(all_labels, labels, axis = 0)\n",
    "    except:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "B_zeta_train = B_zeta.predict(x = all_images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(str(extracted_coefficients_directory + 'B_zeta_train.npy'), B_zeta_train)\n",
    "np.save(str(extracted_coefficients_directory + 'labels_train.npy'), all_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = B_zeta_train.dot(beta[0]) + beta[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.scatter(pred, all_labels, alpha = 0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
