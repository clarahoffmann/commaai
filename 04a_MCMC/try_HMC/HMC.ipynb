{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from random import random\n",
    "import helpers as hlp\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Want to sample from three variables:\n",
    "1. $\\lambda$\n",
    "2. $\\tau$\n",
    "3. $\\beta$\n",
    "\n",
    "-> these values are then averaged to get the Monte-Carlo estimator\n",
    "-> first: what is density of $\\beta$?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import data from DNN training\n",
    "extracted_coefficients_directory = '../../../data/commaai/extracted_coefficients/20201027_filtered_gaussian_resampled/'\n",
    "B_zeta_path = str(extracted_coefficients_directory + 'Bzeta/B_zeta.npy')\n",
    "beta_path = str(extracted_coefficients_directory + 'beta/beta.csv')\n",
    "z_path = str(extracted_coefficients_directory + 'Bzeta/tr_labels.npy')\n",
    "beta = np.genfromtxt(beta_path, delimiter=',')\n",
    "B_zeta = np.load(B_zeta_path)\n",
    "B_zeta = B_zeta.reshape(B_zeta.shape[0], beta.shape[0])\n",
    "z = np.load(z_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "beta = np.repeat(0,10)\n",
    "# number of samples we want to produce\n",
    "M = 10\n",
    "L = 2\n",
    "\n",
    "# number of parameters of theta\n",
    "q = B_zeta.shape[1]*2 + 1\n",
    "p = B_zeta.shape[1]\n",
    "\n",
    "n = B_zeta.shape[0]\n",
    "\n",
    "# start values for beta, lambda, tau\n",
    "# beta is taken from trained network and other two\n",
    "# are initialized randomly\n",
    "theta_m_1 = np.append(np.append(beta, np.random.rand(B_zeta.shape[1],)), np.random.rand(1,))\n",
    "\n",
    "# stepsize\n",
    "epsilon = 0.1\n",
    "\n",
    "r_m = np.zeros(theta_m_1.shape[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " need to write functions for\n",
    "- log-density of $\\log \\lambda_j^2$\n",
    "- gradient of log-density of $\\log \\lambda_j^2$\n",
    "\n",
    "- log-density of $\\log \\tau$\n",
    "- gradient of $\\log \\tau$\n",
    "\n",
    "- log-density of $\\beta$\n",
    "- gradient of $\\beta$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log density of tau\n",
    "def log_density_tau(tau, p, Lambda_vec):\n",
    "    return(-(p-1)*log(tau) - log(1 + tau**2) - np.sum(Lambda**2)/(tau**2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# log density of lambda_j\n",
    "def log_density_lambda_j(const, lambda_j, beta_j, S, z, B, beta_t):\n",
    "    const = -(1/2)*np.sum(np.log(S**2)) - (1/2)*z.dot(np.linalg.solve(S.dot(S))).dot(z)  + beta_t.dot(B.T).dot(S**(-1)).dot(z)\n",
    "    return( const - (1/2)*(log(lambda_j**2)  + (beta_j**2)/(lambda_j**2) + 2*log(1 + (lambda_j**2)/(tau**2) + (1/2)*lambda_j)))\n",
    "# last term might be wrong bc doesnt exist in kleins paper...\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.        , 0.        , 0.        , 0.        , 0.        ,\n",
       "       0.69889898, 0.65634294, 0.06012714, 0.08063367, 0.37048848,\n",
       "       0.4406087 , 0.93624851, 0.19854791, 0.8774273 , 0.44997246,\n",
       "       0.19465204])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "theta_m_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Leapfrog(theta, r, epsilon, n, z, p):\n",
    "    \n",
    "    # compute gradient with theta\n",
    "    Delta_theta = hlp.Delta_theta(theta, B_zeta, n, z, p)\n",
    "    \n",
    "    # update momentum\n",
    "    r_tilde = r + (epsilon/2)*Delta_theta\n",
    "    \n",
    "    # update theta\n",
    "    theta_tilde = theta + epsilon*r_tilde\n",
    "    \n",
    "    # compute updated gradient\n",
    "    Delta_theta_tilde = hlp.Delta_theta(theta_tilde, B_zeta, n, z, p)\n",
    "    \n",
    "    # update momentum again\n",
    "    r_tilde = r_tilde + (epsilon/2)*Delta_theta_tilde\n",
    "    \n",
    "    return(theta_tilde, r_tilde)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r0 = np.repeat(None, M)\n",
    "theta_tilde = np.repeat(None, M)\n",
    "r_tilde = np.repeat(None, M)\n",
    "log_dens =  np.repeat(None, M)\n",
    "alpha = np.repeat(None, M)\n",
    "theta_m_1 = np.repeat(None, M)\n",
    "r_m = np.repeat(None, M)\n",
    "theta_m_1[0] = np.append(np.append(beta, np.random.rand(B_zeta.shape[1],)), np.random.rand(1,))\n",
    "\n",
    "acc = []\n",
    "# loop over number of samples that we want to produce\n",
    "for m in tqdm(range(0, M)):\n",
    "    print(theta_m_1[0].shape)\n",
    "    \n",
    "    # Update S\n",
    "    # draw momentum from normal distribution\n",
    "    r0[m] = np.random.multivariate_normal(np.zeros(q), np.identity(q), 1)\n",
    "    \n",
    "    # set new parameters\n",
    "    theta_tilde[m] = theta_m_1[m].reshape(21,)\n",
    "    r_tilde[m] = r0[m]\n",
    "    \n",
    "    # generate proposal through L leapfrog updates \n",
    "    for i in range(0,L):\n",
    "        theta_tilde[m], r_tilde[m] = Leapfrog(theta_tilde[m], r_tilde[m], epsilon, n, z, p)\n",
    "    \n",
    "    # probability that proposal is accepted\n",
    "    log_dens[m] = log_density(theta_tilde[m])\n",
    "    alpha[m] = min([1, (np.exp(log_dens[m] - r_tilde[m]*r_tilde[m]*1/2))/(log_dens[m] - r0[m]*r0[m]*1/2)])\n",
    "    \n",
    "    decision = rand()\n",
    "    if rand <= alpha:\n",
    "        theta_m_1[m + 1] = theta_tilde[m]\n",
    "        r_m[m + 1] = - r_tilde[m]\n",
    "        acc.append(1)\n",
    "    else:\n",
    "        theta_m_1[m + 1] = theta_tilde[m - 1]\n",
    "        r_m[m + 1] = - r_tilde[m - 1]\n",
    "        acc.append(0)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "theta_m_1.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
